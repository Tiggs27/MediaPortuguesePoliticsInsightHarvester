{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_driver():\n",
    "    brave_path = r\"C:\\Program Files\\BraveSoftware\\Brave-Browser\\Application\\brave.exe\"\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    options = Options()\n",
    "    options.binary_location = brave_path\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_source(url, driver):\n",
    "    driver.get(url)\n",
    "    time.sleep(10)\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    return driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_articles_jornal_noticias(soup):\n",
    "    divs_itc001 = soup.find_all(lambda tag: (\n",
    "        tag.name == \"div\" and \n",
    "        tag.get(\"data-instance\") == \"i01\" and \n",
    "        \"ITC001\" in tag.get(\"class\", []) and \n",
    "        \"light\" in tag.get(\"class\", [])\n",
    "    ))\n",
    "    divs_hc002 = soup.find_all(lambda tag: (\n",
    "        tag.name == \"div\" and \n",
    "        \"HC002\" in tag.get(\"class\", []) and \n",
    "        \"light\" in tag.get(\"class\", [])\n",
    "    ))\n",
    "    divs_pc001 = soup.find_all(lambda tag: (\n",
    "        tag.name == \"div\" and \n",
    "        tag.get(\"data-instance\") == \"i01\" and \n",
    "        \"PC001\" in tag.get(\"class\", []) and \n",
    "        \"light\" in tag.get(\"class\", [])\n",
    "    ))\n",
    "    divs_hc002data = soup.find_all(lambda tag: (\n",
    "        tag.name == \"div\" and \n",
    "        tag.get(\"data-instance\") == \"i02\" and \n",
    "        \"HC002\" in tag.get(\"class\", []) and \n",
    "        \"light\" in tag.get(\"class\", [])\n",
    "    ))\n",
    "    divs_itc002 = soup.find_all(lambda tag: (\n",
    "        tag.name == \"div\" and \n",
    "        tag.get(\"data-instance\") == \"i04\" and \n",
    "        \"ITC002\" in tag.get(\"class\", []) and \n",
    "        \"light\" in tag.get(\"class\", [])\n",
    "    ))\n",
    "    \n",
    "    print(f\"HC002 light none found: {len(divs_hc002data)}\")\n",
    "    print(f\"ITC001 light none found: {len(divs_itc001)}\")\n",
    "    print(f\"PC001 light corners-square none hover-scale found: {len(divs_pc001)}\")\n",
    "    print(f\"ITC002 light corners-square none found: {len(divs_itc002)}\")\n",
    "    print(f\"HC002 light none found: {len(divs_hc002data)}\")\n",
    "\n",
    "    all_divs = divs_hc002 + divs_itc001 + divs_pc001 +  divs_itc002 + divs_hc002data\n",
    "\n",
    "    articles = []\n",
    "    for div in all_divs:\n",
    "        #print(div)\n",
    "        a_tag = div.find(\"a\")\n",
    "        h2title, category = None, None\n",
    "        h2title = div.find(\"h2\",class_=\"title\")\n",
    "        category = div.find(\"div\", class_=\"info\")\n",
    "\n",
    "        if a_tag:\n",
    "\n",
    "            h2title = h2title.get_text(strip=True)\n",
    "            category = category.get_text(strip=True)\n",
    "            link = a_tag[\"href\"]\n",
    "            \n",
    "            full_link = f\"https://www.jn.pt{link}\"\n",
    "\n",
    "            articles.append({\"title\": h2title, \"link\": full_link, \"category\": category})\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_and_find_element(driver,locator,scroll_amount=500):\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    scroll_position = 0\n",
    "    print(f\"Entro aqui também\")\n",
    "    while True:\n",
    "        try:\n",
    "            print(f\"Entro aqui também 2\")\n",
    "            element = wait.until(EC.presence_of_element_located(locator))\n",
    "            print(f\"Encontrei o element -> {element}\")\n",
    "            return element\n",
    "        except:\n",
    "            print(f\"Entro aqui também 3 \")\n",
    "            driver.execute_script(f\"window.scrollTo(0,{scroll_position})\")\n",
    "            scroll_position += scroll_amount\n",
    "            time.sleep(20)\n",
    "\n",
    "            if scroll_position > driver.execute_script(\"return document.body.scrollHeight\"):\n",
    "                print(\"End of file reached, it didnt find the element\")\n",
    "                return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_full_article(article_url, driver):\n",
    "    \"\"\"Visit an article URL and extract the full text content.\"\"\"\n",
    "    page_source = get_page_source(article_url, driver)\n",
    "    soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "    paragraphs = soup.find_all(\"p\")\n",
    "    return \"\\n\".join([p.get_text(strip=True) for p in paragraphs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estou a entrar\n",
      "Entro aqui também\n",
      "Entro aqui também 2\n",
      "Encontrei o element -> <selenium.webdriver.remote.webelement.WebElement (session=\"6f648a1250ec320f9651f0d2ccbdb6b4\", element=\"f.4A41CC3EDD1C367C5BF546740955C48A.d.9B97BFB76C0528D20246B54CF2CD5C16.e.621\")>\n",
      "Conteudo da funcao -> <selenium.webdriver.remote.webelement.WebElement (session=\"6f648a1250ec320f9651f0d2ccbdb6b4\", element=\"f.4A41CC3EDD1C367C5BF546740955C48A.d.9B97BFB76C0528D20246B54CF2CD5C16.e.621\")>\n",
      "Crise Politica button pressed.\n",
      "HC002 light none found: 11\n",
      "ITC001 light none found: 1\n",
      "PC001 light corners-square none hover-scale found: 9\n",
      "ITC002 light corners-square none found: 68\n",
      "HC002 light none found: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Licença parental e acesso de estrangeiros ao S...</td>\n",
       "      <td>https://www.jn.pt/6220613528/licenca-parental-...</td>\n",
       "      <td>Política</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Montenegro convicto de que Portugal \"vai tirar...</td>\n",
       "      <td>https://www.jn.pt/6202629582/montenegro-convic...</td>\n",
       "      <td>Política</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "33  Licença parental e acesso de estrangeiros ao S...   \n",
       "35  Montenegro convicto de que Portugal \"vai tirar...   \n",
       "\n",
       "                                                 link  category  \n",
       "33  https://www.jn.pt/6220613528/licenca-parental-...  Política  \n",
       "35  https://www.jn.pt/6202629582/montenegro-convic...  Política  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    url = \"https://www.jn.pt/\"\n",
    "    driver = setup_driver()\n",
    "\n",
    "    get_page_source(url, driver)\n",
    "    driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[2]/div[2]/div[2]/button[1]').click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    total_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    quarter_height = total_height / 4\n",
    "    current_scroll_position = 0\n",
    "\n",
    "    for _ in range(4):\n",
    "        current_scroll_position += quarter_height\n",
    "        driver.execute_script(f\"window.scrollTo(0, {current_scroll_position});\")\n",
    "        time.sleep(5) #Add a small delay, adjust as needed\n",
    "\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "    time.sleep(1)\n",
    "    driver.execute_script(f\"window.scrollTo(0, 0);\",\"\")\n",
    "    time.sleep(1)\n",
    "\n",
    "    try:\n",
    "        print(f\"Estou a entrar\")\n",
    "        element_crise_politica = scroll_and_find_element(driver,(By.XPATH, '//*[@id=\"crise-politica\"]/div/div/div/div[1]/div/a'))\n",
    "        print(f\"Conteudo da funcao -> {element_crise_politica}\")\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", element_crise_politica)\n",
    "        time.sleep(2)\n",
    "        element_crise_politica.click()\n",
    "        time.sleep(10)\n",
    "        print(f\"Crise Politica button pressed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Crise Politica couldnt be pressed\")\n",
    "\n",
    "    current_scroll_position = 0\n",
    "    \n",
    "    for _ in range(4):\n",
    "        current_scroll_position += quarter_height\n",
    "        driver.execute_script(f\"window.scrollTo(0, {current_scroll_position});\")\n",
    "        time.sleep(random.randint(1,2))\n",
    "\n",
    "    articles = extract_articles_jornal_noticias(soup)\n",
    "\n",
    "\n",
    "    # for article in articles:\n",
    "    #     article[\"article_content\"] = extract_full_article(article[\"link\"], driver)\n",
    "\n",
    "    #     print(f\"Title: {article['title']}\")\n",
    "    #     print(f\"Link: {article['link']}\")\n",
    "    #     print(f\"Content Inside Div: {article['div_content']}\")\n",
    "    #     print(f\"Full Article Content:\\n{article['article_content'][:500]}...\")\n",
    "    #     print(\"-\" * 100)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    df = pd.DataFrame(articles)\n",
    "\n",
    "    df = df.drop_duplicates(subset=['title'],ignore_index=True)\n",
    "\n",
    "    df_politica = df[df['category'].isin(['Politica','Política','politica']) ]\n",
    "    display(df_politica)\n",
    "\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "All",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
